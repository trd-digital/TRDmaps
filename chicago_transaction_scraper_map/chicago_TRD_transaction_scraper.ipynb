{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a811c0dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c1dd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386568bb",
   "metadata": {},
   "source": [
    "## Set Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5bb7d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 1600)\n",
    "pd.set_option('display.max_colwidth', None) ### Default 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c2ffd",
   "metadata": {},
   "source": [
    "## Data Read-in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e72640",
   "metadata": {},
   "source": [
    "<em>All</em> Chicago URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8eaced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Chicago URLS by year - 2017.csv',header=None)\n",
    "df2 = pd.read_csv('Chicago URLS by year - 2018.csv',header=None)\n",
    "df3 = pd.read_csv('Chicago URLS by year - 2019.csv',header=None)\n",
    "# df4 = pd.read_csv('Chicago URLS by year - 2020.csv',header=None)\n",
    "df5 = pd.read_csv('Chicago URLS by year - 2021.csv',header=None)\n",
    "df6 = pd.read_csv('Chicago URLS by year - 2022.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e6f0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df,df2,df3,df5,df6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abd59738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0de72cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "936425b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=317106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=340311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=335204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=350083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=174163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=353875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=353926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=353989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=354016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>https://therealdeal.com/chicago/?p=354064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10776 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "0      https://therealdeal.com/chicago/?p=317106\n",
       "1      https://therealdeal.com/chicago/?p=340311\n",
       "2      https://therealdeal.com/chicago/?p=335204\n",
       "3      https://therealdeal.com/chicago/?p=350083\n",
       "4      https://therealdeal.com/chicago/?p=174163\n",
       "...                                          ...\n",
       "10771  https://therealdeal.com/chicago/?p=353875\n",
       "10772  https://therealdeal.com/chicago/?p=353926\n",
       "10773  https://therealdeal.com/chicago/?p=353989\n",
       "10774  https://therealdeal.com/chicago/?p=354016\n",
       "10775  https://therealdeal.com/chicago/?p=354064\n",
       "\n",
       "[10776 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "359b3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'URL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b49a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Original Data set - kept for backup\n",
    "# df = pd.read_csv('TRD_CHI-Coverage-Valid-2022-12-01 - Table.csv')\n",
    "# df = df.drop(columns='Last crawled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdf697",
   "metadata": {},
   "source": [
    "## Test Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8eb6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = requests.get('https://therealdeal.com/chicago/2022/04/25/first-market-rate-modular-home-available-in-chicagos-south-shore/')\n",
    "# soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b73bb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find('h1').text.strip() ### Title\n",
    "# soup.find('h2').text.strip() ### Subhead\n",
    "# soup.find('div', class_='col-7 col-md-3 order-md-3 text-right').text.strip() ### Pub_Date\n",
    "# soup.find_all('p')[2].text.strip() ### Lede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88c71566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# story_text = soup.find_all('p')[2:]\n",
    "# story_text_clean = []\n",
    "# for p in story_text:\n",
    "#     p = p.text.strip()\n",
    "#     story_text_clean.append(p)\n",
    "# story_text_clean = [''.join(story_text_clean)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c00968",
   "metadata": {},
   "source": [
    "TO DO: Fix image scraper to get PNGs...or succesfull append something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12377c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = soup.find_all('img')\n",
    "# for image in images:\n",
    "#     if 'jpg' in image['src']:\n",
    "#         print(image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e690411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = soup.find_all('img')\n",
    "# png_list = []\n",
    "# for image in images:\n",
    "#     if 'png' in image['src']:\n",
    "#         png_list.append(image['src'])\n",
    "# print(png_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb82010",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba246f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Lists\n",
    "\n",
    "hed_list = []\n",
    "dek_list = []\n",
    "pub_date_list = []\n",
    "lede_list = []\n",
    "story_text_list = []\n",
    "entire_soup_list = []\n",
    "\n",
    "# image_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b991b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5481\n",
      "https://therealdeal.com/chicago/?p=268057\n",
      "DEK fail https://therealdeal.com/chicago/?p=268057 ERROR: 'NoneType' object has no attribute 'text'\n",
      "PUB_DATE fail https://therealdeal.com/chicago/?p=268057 ERROR: 'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for url in df['URL']:\n",
    "    if counter > 12000:\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            counter = counter + 1\n",
    "            clear_output(wait=True)\n",
    "            print(counter)\n",
    "            print(url)\n",
    "            \n",
    "            ####################\n",
    "            # HED #\n",
    "            \n",
    "            try:\n",
    "#                 print(soup.find('h1').text.strip())\n",
    "                hed_1 = soup.find('h1').text.strip()\n",
    "                hed_list.append(hed_1)\n",
    "            except Exception as e:\n",
    "                print(f'HED fail {url} ERROR: {e}')\n",
    "                hed_list.append(f'HED fail {url} ERROR: {e}')\n",
    "            \n",
    "            ####################\n",
    "            # DEK #\n",
    "            \n",
    "            try:\n",
    "#                 print(soup.find('h2').text.strip())\n",
    "                dek_1 = soup.find('h2').text.strip()\n",
    "                dek_list.append(dek_1)\n",
    "            except Exception as e:\n",
    "                print(f'DEK fail {url} ERROR: {e}')\n",
    "                dek_list.append(f'DEK fail {url} ERROR: {e}')\n",
    "                \n",
    "            ####################  \n",
    "            # PUB_DATE #\n",
    "            \n",
    "            try:\n",
    "#                 print(soup.find('div', class_='col-7 col-md-3 order-md-3 text-right').text.strip())\n",
    "                pub_date_1 = soup.find('div', class_='col-7 col-md-3 order-md-3 text-right').text.strip()\n",
    "                pub_date_list.append(pub_date_1)\n",
    "            except Exception as e:\n",
    "                print(f'PUB_DATE fail {url} ERROR: {e}')\n",
    "                pub_date_list.append(f'PUB_DATE fail {url} ERROR: {e}')\n",
    "            \n",
    "            ####################\n",
    "            # LEDE #\n",
    "            \n",
    "            try:  \n",
    "#                 print(soup.find_all('p')[2].text.strip())\n",
    "                lede_1 = soup.find_all('p')[2].text.strip()\n",
    "                lede_list.append(lede_1)\n",
    "            except Exception as e:\n",
    "                print(f'LEDE fail {url} ERROR: {e}')\n",
    "                lede_list.append(f'LEDE fail {url} ERROR: {e}')\n",
    "                \n",
    "            ####################\n",
    "            # STORY TEXT #\n",
    "                \n",
    "            try:\n",
    "                story_text = soup.find_all('p')[1:]\n",
    "                story_text_clean = []\n",
    "                for p in story_text:\n",
    "                    p = p.text.strip()\n",
    "                    story_text_clean.append(p)\n",
    "                story_text_clean = [''.join(story_text_clean)]\n",
    "                story_text_list.append(story_text_clean)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'STORY TEXT fail {url} ERROR: {e}')\n",
    "                story_text_list.append(f'STORY TEXT fail {url} ERROR: {e}')\n",
    "                \n",
    "            ####################\n",
    "            # ENTIRE SOUP #\n",
    "            \n",
    "            try:\n",
    "                entire_soup_list.append(soup)\n",
    "            except Exception as e:\n",
    "                entire_soup_list.append(f'SOUP FAIL {url} ERROR: {e}')\n",
    "        \n",
    "#             print('----------')\n",
    "        except Exception as e:\n",
    "            print(f'{url} - FAIL: {e}')\n",
    "            hed_list.append(f'{url} - FAIL: {e}')\n",
    "            dek_list.append(f'{url} - FAIL: {e}')\n",
    "            pub_date_list.append(f'{url} - FAIL: {e}')\n",
    "            lede_list.append(f'{url} - FAIL: {e}')\n",
    "            story_text_list.append(f'{url} - FAIL: {e}')\n",
    "            entire_soup_list.append(f'{url} - FAIL: {e}')\n",
    "            ####################\n",
    "            # IMAGES #\n",
    "            \n",
    "#             try:            \n",
    "#                 images = soup.find_all('img')\n",
    "#                 image_found = False\n",
    "#                 try:\n",
    "#                     while image_found == False:\n",
    "#                         png_list = []\n",
    "#                         for image in images:\n",
    "#                             if 'jpg' in image['src']:\n",
    "#                                 image_list.append(image['src'])\n",
    "#                                 print(image['src'])\n",
    "#                                 image_found = True\n",
    "#                             break\n",
    "#                         if image_found == False:\n",
    "#                             for image in images:\n",
    "#                                 if 'png' in image['src']:\n",
    "#                                     png_list.append(image['src'])\n",
    "#                                     image_found = True\n",
    "#                             image_list.append(png_list[-1])\n",
    "#                             print(png_list[-1])\n",
    "#                 except Exception as e:\n",
    "#                     print(f'No dice: {e}')\n",
    "#                 print('------')\n",
    "#             except Exception as e:\n",
    "#                 print('find_image_fail')\n",
    "            \n",
    "            ####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78136bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hed_list))\n",
    "print('---------')\n",
    "print(len(dek_list))\n",
    "print('---------')\n",
    "print(len(pub_date_list))\n",
    "print('---------')\n",
    "print(len(lede_list))\n",
    "print('---------')\n",
    "print(len(story_text_list))\n",
    "print('---------')\n",
    "print(len(entire_soup_list))\n",
    "print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eea6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8424b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HED'] = hed_list\n",
    "df['DEK'] = dek_list\n",
    "df['PUB_DATE'] = pub_date_list\n",
    "df['LEDE'] = lede_list\n",
    "df['STORY_TEXT'] = story_text_list\n",
    "df['SOUP'] = entire_soup_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d16318",
   "metadata": {},
   "source": [
    "## Parser Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09183b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STORY_TEXT'] = df['STORY_TEXT'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL'].iloc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRESS'] = df['STORY_TEXT'].str.extract(r'(?P<ADDRESS>[1-9][0-9]* (?:\\w+\\W+){1,6}(?:Road|Rd|Avenue|Ave|Boulevard|Blvd|Street|St|Place|Drive|Dr|Huron))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685959a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['ADDRESS'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e210ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['URL','ADDRESS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ef211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns='SOUP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Chicago_sample.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
